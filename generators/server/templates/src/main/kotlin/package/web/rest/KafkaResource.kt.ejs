<%#
 Copyright 2013-2020 the original author or authors from the JHipster project.

 This file is part of the JHipster project, see https://www.jhipster.tech/
 for more information.

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-%>
package <%=packageName%>.web.rest

import <%= packageName %>.config.KafkaProperties
import org.apache.kafka.clients.consumer.ConsumerRecord
<%_ if (!reactive) { _%>
import org.apache.kafka.clients.consumer.ConsumerRecords
import org.apache.kafka.clients.consumer.KafkaConsumer
import org.apache.kafka.clients.producer.KafkaProducer
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.clients.producer.RecordMetadata
<%_ }  _%>
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import org.springframework.web.bind.annotation.PathVariable
import org.springframework.web.bind.annotation.PostMapping
import org.springframework.web.bind.annotation.GetMapping
import org.springframework.web.bind.annotation.RequestMapping
import org.springframework.web.bind.annotation.RequestParam
import org.springframework.web.bind.annotation.RestController
<%_ if (reactive) { _%>
import reactor.core.publisher.Flux
import reactor.core.publisher.Mono
import reactor.kafka.receiver.KafkaReceiver
import reactor.kafka.receiver.ReceiverOptions
import reactor.kafka.sender.KafkaSender
import reactor.kafka.sender.SenderOptions
import reactor.kafka.sender.SenderRecord
import reactor.kafka.sender.SenderResult
<%_ }  _%>
<%_ if (!reactive) { _%>
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter
<%_ }  _%>

<%_ if (!reactive) { _%>
import java.time.Duration
<%_ }  _%>
import java.time.Instant
import java.util.concurrent.ExecutionException
<%_ if (!reactive) { _%>
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors
<%_ }  _%>


@RestController
@RequestMapping("/api/<%= dasherizedBaseName %>-kafka")
class <%= upperFirstCamelCase(baseName) %>KafkaResource(
    private val kafkaProperties: KafkaProperties
) {

    private val log = LoggerFactory.getLogger(javaClass)
    <%_ if (!reactive) { _%>
    private lateinit var producer: KafkaProducer<String, String>
    private lateinit var sseExecutorService: ExecutorService
    <%_ } else { _%>
    private lateinit var sender: KafkaSender<String, String>
    <%_ }  _%>

    init {
        <%_ if (!reactive) { _%>
        producer = KafkaProducer<String, String>(kafkaProperties.getProducerProps())
        sseExecutorService = Executors.newCachedThreadPool()
        <%_ } else { _%>
        sender = KafkaSender.create(SenderOptions.create(kafkaProperties.getProducerProps()))
        <%_ }  _%>
    }

    @PostMapping("/publish/{topic}")
    @Throws(*[ExecutionException::class, InterruptedException::class])
    fun publish(@PathVariable topic: String, @RequestParam message: String, @RequestParam(required = false) key: String?): <% if (!reactive) { %>PublishResult<% } else { %>Mono<PublishResult><% }  %> {
        log.debug("REST request to send to Kafka topic $topic with key $key the message : $message")
        <%_ if (!reactive) { _%>
        val metadata = producer.send(ProducerRecord(topic, key, message)).get()
        return PublishResult(metadata.topic(), metadata.partition(), metadata.offset(), Instant.ofEpochMilli(metadata.timestamp()))
        <%_ } else { _%>
        return Mono.just(SenderRecord.create(topic, null, null, key, message, null))
            .as(sender::send)
            .next()
            .map(SenderResult::recordMetadata)
            .map { metadata -> 
                PublishResult(metadata.topic(), metadata.partition(), metadata.offset(), Instant.ofEpochMilli(metadata.timestamp()))
            }
        <%_ }  _%>
    }

    @GetMapping("/consume")
    fun consume(@RequestParam("topic") topics: List<String>, @RequestParam consumerParams: Map<String, String>): SseEmitter {
        log.debug("REST request to consume records from Kafka topics $topics")
        val consumerProps = kafkaProperties.getConsumerProps()
        consumerProps.putAll(consumerParams)
        consumerProps.remove("topic")

        <%_ if (!reactive) { _%>
        val emitter = SseEmitter(0L)
        sseExecutorService.execute {
            val consumer = KafkaConsumer<String, String>(consumerProps)
            emitter.onCompletion(consumer::close)
            consumer.subscribe(topics)
            var exitLoop = false

            while (!exitLoop) {
                try {
                    val records = consumer.poll(Duration.ofSeconds(5L))
                    records.forEach { emitter.send(it.value()) }
                    emitter.send(SseEmitter.event().comment(""))
                } catch (ex: Exception) {
                    log.trace("Complete with error ${ex.message}", ex)
                    emitter.completeWithError(ex)
                    exitLoop = true
                }
            }
            consumer.close()
            emitter.complete()
        }
        return emitter
        <%_ } else { _%>
        val receiverOptions = ReceiverOptions.<String, String>create(consumerProps).subscription(topics)
        return KafkaReceiver.create(receiverOptions)
                .receive()
                .map(ConsumerRecord::value)
        <%_ }  _%>
    }

    class PublishResult(
        val topic: String,
        val partition: Int,
        val offset: Long,
        val timestamp: Instant
    )
}
